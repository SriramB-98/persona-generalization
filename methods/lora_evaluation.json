{
  "raw": {
    "within_eval_settings": {
      "mean_rho": 0.8547619047619047,
      "n": 42,
      "details": [
        {
          "persona": "angry",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "angry",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "angry",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "angry",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.6
        },
        {
          "persona": "angry",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "angry",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "bureaucratic",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "bureaucratic",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "bureaucratic",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "bureaucratic",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "bureaucratic",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "bureaucratic",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "confused",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.3
        },
        {
          "persona": "confused",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.7
        },
        {
          "persona": "confused",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "confused",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "confused",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "confused",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "curt",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "curt",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.49999999999999994
        },
        {
          "persona": "curt",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.7
        },
        {
          "persona": "curt",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.49999999999999994
        },
        {
          "persona": "curt",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "curt",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.7
        },
        {
          "persona": "disappointed",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.49999999999999994
        },
        {
          "persona": "disappointed",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "disappointed",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "disappointed",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "disappointed",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.6
        },
        {
          "persona": "mocking",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "mocking",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "mocking",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "mocking",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.7
        },
        {
          "persona": "nervous",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "nervous",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "nervous",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "nervous",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "nervous",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.9999999999999999
        }
      ]
    },
    "within_personas": {
      "mean_rho": 0.8601190476190478,
      "n": 36,
      "details": [
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 0.7500000000000002
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.642857142857143
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.7857142857142859
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.7500000000000002
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 0.9642857142857145
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 0.7857142857142859
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.9642857142857145
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.25
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.5
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.9642857142857145
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 0.9642857142857145
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.7857142857142859
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "refusal",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "refusal",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.9642857142857145
        },
        {
          "train_setting": "refusal",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "refusal",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "refusal",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.9642857142857145
        },
        {
          "train_setting": "refusal",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.8571428571428573
        }
      ]
    },
    "within_train_settings": {
      "mean_rho": 0.7499999999999999,
      "n": 42,
      "details": [
        {
          "persona": "angry",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.7
        },
        {
          "persona": "angry",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "angry",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.6
        },
        {
          "persona": "angry",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.6
        },
        {
          "persona": "angry",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.7
        },
        {
          "persona": "angry",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.39999999999999997
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.3
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.19999999999999998
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "confused",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "confused",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "confused",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "confused",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.3
        },
        {
          "persona": "confused",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.7
        },
        {
          "persona": "confused",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "curt",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "curt",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.49999999999999994
        },
        {
          "persona": "curt",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.0
        },
        {
          "persona": "curt",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.7
        },
        {
          "persona": "curt",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "curt",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "disappointed",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "mocking",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "mocking",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.6
        },
        {
          "persona": "mocking",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.3
        },
        {
          "persona": "nervous",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.49999999999999994
        },
        {
          "persona": "nervous",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.6
        },
        {
          "persona": "nervous",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        }
      ]
    }
  },
  "corrected": {
    "within_eval_settings": {
      "mean_rho": 0.8357142857142856,
      "n": 42,
      "details": [
        {
          "persona": "angry",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "angry",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "angry",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "angry",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.6
        },
        {
          "persona": "angry",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "angry",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "bureaucratic",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "bureaucratic",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "bureaucratic",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "bureaucratic",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.7
        },
        {
          "persona": "bureaucratic",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "bureaucratic",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "confused",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": -0.09999999999999999
        },
        {
          "persona": "confused",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.7
        },
        {
          "persona": "confused",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "confused",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "confused",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "confused",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "curt",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "curt",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.49999999999999994
        },
        {
          "persona": "curt",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.7
        },
        {
          "persona": "curt",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.6
        },
        {
          "persona": "curt",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "curt",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.09999999999999999
        },
        {
          "persona": "disappointed",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "disappointed",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "disappointed",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "disappointed",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "disappointed",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.6
        },
        {
          "persona": "mocking",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "mocking",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "mocking",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "mocking",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "train_setting": "diverse_open_ended",
          "n_evals": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "nervous",
          "train_setting": "diverse_open_ended_es",
          "n_evals": 5,
          "rho": 0.7
        },
        {
          "persona": "nervous",
          "train_setting": "diverse_open_ended_zh",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "train_setting": "factual_questions",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "train_setting": "normal_requests",
          "n_evals": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "train_setting": "refusal",
          "n_evals": 5,
          "rho": 0.9999999999999999
        }
      ]
    },
    "within_personas": {
      "mean_rho": 0.8611111111111112,
      "n": 36,
      "details": [
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 0.28571428571428575
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.4642857142857144
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.7500000000000002
        },
        {
          "train_setting": "diverse_open_ended",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.7857142857142859
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.9642857142857145
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "diverse_open_ended_es",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.5714285714285715
        },
        {
          "train_setting": "diverse_open_ended_zh",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.7857142857142859
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "factual_questions",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 0.9642857142857145
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.7142857142857144
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.8571428571428573
        },
        {
          "train_setting": "normal_requests",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.7500000000000002
        },
        {
          "train_setting": "refusal",
          "eval_setting": "diverse_open_ended",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "refusal",
          "eval_setting": "factual_questions",
          "n_personas": 7,
          "rho": 0.8928571428571429
        },
        {
          "train_setting": "refusal",
          "eval_setting": "harmful_requests",
          "n_personas": 7,
          "rho": 1.0
        },
        {
          "train_setting": "refusal",
          "eval_setting": "normal_requests",
          "n_personas": 7,
          "rho": 0.9285714285714288
        },
        {
          "train_setting": "refusal",
          "eval_setting": "open_ended_chinese",
          "n_personas": 7,
          "rho": 0.9642857142857145
        },
        {
          "train_setting": "refusal",
          "eval_setting": "open_ended_spanish",
          "n_personas": 7,
          "rho": 0.8571428571428573
        }
      ]
    },
    "within_train_settings": {
      "mean_rho": 0.7499999999999999,
      "n": 42,
      "details": [
        {
          "persona": "angry",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.7
        },
        {
          "persona": "angry",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "angry",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.6
        },
        {
          "persona": "angry",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.6
        },
        {
          "persona": "angry",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.7
        },
        {
          "persona": "angry",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.39999999999999997
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.3
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.7999999999999999
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.19999999999999998
        },
        {
          "persona": "bureaucratic",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "confused",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "confused",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "confused",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "confused",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.3
        },
        {
          "persona": "confused",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.7
        },
        {
          "persona": "confused",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "curt",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "curt",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.49999999999999994
        },
        {
          "persona": "curt",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.0
        },
        {
          "persona": "curt",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.7
        },
        {
          "persona": "curt",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "curt",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "disappointed",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "disappointed",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "mocking",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "mocking",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.8999999999999998
        },
        {
          "persona": "mocking",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.6
        },
        {
          "persona": "mocking",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.3
        },
        {
          "persona": "nervous",
          "eval_setting": "diverse_open_ended",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "eval_setting": "factual_questions",
          "n_trains": 5,
          "rho": 0.49999999999999994
        },
        {
          "persona": "nervous",
          "eval_setting": "harmful_requests",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "eval_setting": "normal_requests",
          "n_trains": 5,
          "rho": 0.9999999999999999
        },
        {
          "persona": "nervous",
          "eval_setting": "open_ended_chinese",
          "n_trains": 5,
          "rho": 0.6
        },
        {
          "persona": "nervous",
          "eval_setting": "open_ended_spanish",
          "n_trains": 5,
          "rho": 0.8999999999999998
        }
      ]
    }
  }
}